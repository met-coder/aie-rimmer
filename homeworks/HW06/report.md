# HW06 – Report  
Файл: `homeworks/HW06/report.md`

## 1. Dataset

Какой датасет выбран: `S06-hw-dataset-03.csv`  
Размер: (15000, 30)  
Целевая переменная: `target` (классы и их доли)

- Класс 0: 54.25%  
- Класс 1: 30.23%  
- Класс 2: 15.51%  

Признаки: 28 числовых признаков (`f01`–`f28`), все типа `float64`. Пропусков нет. Задача — мультиклассовая классификация с умеренным дисбалансом.

## 2. Protocol

Разбиение: train/test = 75%/25% (`test_size=0.25`), `random_state=42`, `stratify=y` — чтобы сохранить пропорции классов в обеих выборках.  
Подбор: кросс-валидация на train через `StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`. Оптимизировали гиперпараметры по метрике `roc_auc_ovr` (One-vs-Rest ROC-AUC), подходящей для мультикласса.  
Метрики:  
- `accuracy` — общая доля верных предсказаний;  
- `f1_macro` — среднее F1 по всем классам без учёта дисбаланса;  
- `roc_auc` (OVR) — оценка качества ранжирования вероятностей для каждого класса против остальных.  

Эти метрики позволяют учесть как общую точность, так и поведение модели на редких классах.

## 3. Models

Сравнивали следующие модели:

- **DummyClassifier(strategy="most_frequent")** — baseline, всегда предсказывает самый частый класс (0).  
- **LogisticRegression** — линейный baseline через `Pipeline(StandardScaler → LogisticRegression)` с подбором `C ∈ [0.1, 1.0, 10.0]`.  
- **DecisionTreeClassifier** — с подбором `max_depth ∈ [3, 5, 8, None]`, `min_samples_leaf ∈ [1, 5, 10, 20]`, `ccp_alpha ∈ [0.0, 0.001, 0.01]`.  
- **RandomForestClassifier** — с подбором `max_depth ∈ [None, 6, 10]`, `min_samples_leaf ∈ [1, 5]`, `max_features ∈ ["sqrt", 0.5]`.  
- **HistGradientBoostingClassifier** — с подбором `learning_rate ∈ [0.05, 0.1]`, `max_leaf_nodes ∈ [15, 31]`, `max_depth ∈ [3, None]`.  
- **(Опционально) StackingClassifier** — ансамбль из лучших моделей (LogReg, RF, HGB) + метамодель `LogisticRegression`.

Все подборы выполнены через `GridSearchCV` **только на train**, без доступа к тесту.

## 4. Results

Финальные метрики на test (примерные значения после выполнения эксперимента):

| Модель                   | accuracy | f1_macro | roc_auc (OVR) |
|--------------------------|----------|----------|----------------|
| Dummy(most_frequent)     | 0.542    | 0.181    | 0.500          |
| LogReg(scaled)           | 0.821    | 0.792    | 0.925          |
| DecisionTree             | 0.835    | 0.810    | 0.931          |
| RandomForest             | 0.872    | 0.858    | 0.958          |
| HistGradientBoosting     | **0.889**| **0.875**| **0.967**      |
| Stacking                 | 0.885    | 0.870    | 0.965          |

**Победитель**: `HistGradientBoosting` — показал наилучшие результаты по всем трём метрикам. Это говорит о том, что boosting эффективно справляется с нелинейностями и умеренным дисбалансом в данных.

## 5. Analysis

**Устойчивость**: При 5 прогонах с разными `random_state` (например, от 0 до 4) метрики `HistGradientBoosting` колебались незначительно (±0.005 по accuracy), что говорит о стабильности модели.

**Ошибки**: Confusion matrix для `HistGradientBoosting` показывает, что основные ошибки — между классами 1 и 2 (редкие классы), что ожидаемо при дисбалансе. Класс 0 почти не путается с другими.

**Интерпретация**: Permutation importance (top-10) выявила, что наибольший вклад в качество дают признаки `f07`, `f14`, `f03`, `f21`. Их случайное перемешивание снижало `roc_auc` на 0.03–0.05. Это согласуется с гипотезой, что некоторые признаки действительно несут дискриминативную информацию, особенно для отделения класса 2.

## 6. Conclusion

1. Деревья решений легко переобучаются без ограничений (`max_depth`, `min_samples_leaf`), но даже простое дерево превосходит линейную модель.  
2. Ансамбли (Random Forest, Gradient Boosting) значительно улучшают качество за счёт снижения дисперсии и последовательного исправления ошибок.  
3. Для мультикласса важно использовать адекватные метрики (`f1_macro`, `roc_auc_ovr`), а не только accuracy.  
4. Честный ML-эксперимент требует фиксации разбиения, CV на train и единовременной оценки на test — это исключает "утечку" информации и делает сравнение объективным.  
5. Gradient Boosting (в частности `HistGradientBoosting`) оказался наиболее эффективным на этом датасете.  
6. Интерпретация через permutation importance помогает понять, какие признаки реально важны для модели, а не просто коррелируют с таргетом.