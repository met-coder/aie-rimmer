# Домашнее задание к семинару 06 (HW06)

Тема: деревья решений и ансамбли (bagging / random forest / boosting / stacking) и честный ML-эксперимент.

HW06 относится к семинару **S06** и выполняется в личном репозитории студента (на основе шаблона курса) в папке `homeworks/HW06/`.

---

## 1. Цель

Закрепить:

- понимание того, как работает **дерево решений** и почему оно легко переобучается;
- навыки контроля сложности дерева (например, через `max_depth`, `min_samples_leaf`, `ccp_alpha`);
- практическое понимание ансамблей:
  - **bagging** как способ уменьшить variance;
  - **Random Forest** как bagging деревьев + случайность по признакам;
  - **boosting** как последовательное улучшение модели;
  - (опционально) **stacking** как композиция разных моделей через метамодель;
- постановку **честного ML-эксперимента**: фиксированный train/test, CV на train для подбора гиперпараметров, единые метрики, фиксация артефактов;
- аккуратное оформление результата в виде ноутбука + короткого отчёта.

---

## 2. Задание

### 2.1. Структура для HW06 (обязательно)

1) В корне репозитория должна быть папка `homeworks/` (создать, если её ещё нет).  
2) Внутри `homeworks/` создать папку `HW06/`.  
3) В папке `homeworks/HW06/` создать:

- основной ноутбук: `HW06.ipynb`
- отчёт: `report.md`
- папку для артефактов: `artifacts/`
  - рекомендуется внутри `artifacts/` завести подпапку `figures/` для графиков

> Имена папок и файлов должны быть **строго такими**, как указано (регистр важен).

---

### 2.2. Учебные датасеты S06 (выбрать один из четырёх)

Для HW06 предоставлены **4 CSV-файла** на выбор:

- `S06-hw-dataset-01.csv` – бинарная классификация, умеренный дисбаланс.  
  Есть несколько "категориальных-подобных" полей (целые значения с малой мощностью), чтобы было что обсудить в контексте деревьев.

- `S06-hw-dataset-02.csv` – бинарная классификация, более "сложная": больше шума/перекрытия классов, плюс добавлены несколько явно нелинейных взаимодействий признаков.  
  Обычно это хороший вариант, чтобы увидеть, как ансамбли выигрывают у базовых моделей.

- `S06-hw-dataset-03.csv` – **мультикласс** (3 класса).  
  Полезен тем, что заставляет аккуратно выбирать метрики и интерпретацию (например, `f1_macro`).

- `S06-hw-dataset-04.csv` – бинарная классификация с **сильным дисбалансом** классов (условно "fraud-like"), много признаков.  
  Как правило, это самый "интересный" датасет: на нём лучше видно, почему одних accuracy мало, и почему ансамбли + правильные метрики действительно важны.

Все данные **полностью синтетические** и не описывают реальных людей или реальные события.

Рекомендации по размещению:

- CSV-файл(ы) можно положить в `homeworks/HW06/` (или в любую другую осмысленную папку данных);
- в ноутбуке путь к CSV должен быть **относительным** (без абсолютных путей к домашним каталогам).

---

### 2.3. Содержание ноутбука `HW06.ipynb` (основная часть)

В ноутбуке `homeworks/HW06/HW06.ipynb` необходимо выполнить следующие шаги.

#### 2.3.1. Загрузка данных и первичный анализ

1) Импортировать библиотеки: `pandas`, `numpy`, `scikit-learn` (модели, CV, метрики), `matplotlib` (для графиков).  
2) Загрузить выбранный CSV в `pandas.DataFrame`.  
3) Зафиксировать минимум:

   - `head()`, `info()`, базовые статистики (`describe()` или аналог);
   - распределение таргета `target` (доли классов);
   - (желательно) проверку пропусков и типы столбцов.

4) Определить:

   - `X` – признаки (все столбцы, кроме `target`; столбец `id` не использовать как признак);
   - `y` – таргет (`target`).

#### 2.3.2. Train/Test-сплит и воспроизводимость

1) Разделить данные на train/test:

   - `test_size` разумный (например, 0.2 или 0.25);
   - обязательно фиксировать `random_state` (например, 42);
   - для классификации – использовать `stratify=y`.

2) Коротко пояснить, почему фиксированный seed и стратификация важны.

#### 2.3.3. Baseline’ы

Сделать минимум два baseline’а:

1) `DummyClassifier` (например, `most_frequent` или `stratified`).  
2) `LogisticRegression` (желательно через `Pipeline(StandardScaler + LogisticRegression)`).

Для обоих baseline’ов посчитать метрики на test (см. ниже) и кратко интерпретировать.

#### 2.3.4. Модели недели 6 (обязательно)

Реализовать и сравнить минимум 3 модели недели 6 (рекомендуется 4):

- `DecisionTreeClassifier`  
  Обязательно показать **контроль сложности** (например, `max_depth` + `min_samples_leaf`; или `ccp_alpha`).

- `RandomForestClassifier`  
  Желательно посмотреть хотя бы одну из "лесных" ручек (`max_features`, `min_samples_leaf`, `max_depth`).

- Один boosting на выбор:
  - `AdaBoostClassifier` или
  - `GradientBoostingClassifier` или
  - `HistGradientBoostingClassifier`

- (опционально) `StackingClassifier` (2-3 базовых модели + метамодель).  
  Важно: делать стекинг **корректно** (через CV-логику; `StackingClassifier` в sklearn это делает).

Подбор гиперпараметров:

- выполнять **только на train** через CV (`GridSearchCV` или аккуратный перебор);
- test использовать **один раз** для финальной оценки.

#### 2.3.5. Метрики качества (обязательно)

Минимальный набор:

- `accuracy` – всегда
- `f1`:
  - для бинарной классификации: обычный `f1`
  - для мультикласса (`S06-hw-dataset-03.csv`): `f1_macro` (или явно пояснить выбранный вариант)
- `ROC-AUC`:
  - обязательно для бинарных датасетов (если модель даёт вероятности)
  - для мультикласса можно:
    - либо не считать ROC-AUC (и явно написать почему),
    - либо посчитать multi-class AUC (например, OVR) и объяснить.

Рекомендуемые диагностические графики:

- ROC-кривая (для бинарных задач);
- confusion matrix;
- (по желанию для дисбаланса, особенно dataset-04) PR-кривая.

#### 2.3.6. Интерпретация (обязательно)

Для **лучшей модели** (по согласованному критерию – например, ROC-AUC на бинарных задачах или `f1_macro` на мультиклассе):

- посчитать **permutation importance** (top-10/15 признаков);
- кратко интерпретировать: какие признаки влияют сильнее и насколько это похоже на ожидания по данным.

---

### 2.4. Артефакты эксперимента (обязательно)

В папке `homeworks/HW06/artifacts/` должны быть:

- `metrics_test.json` (или `.csv`) – финальные метрики на test по всем моделям;
- `search_summaries.json` – лучшие параметры и CV-score для тех моделей, где был подбор;
- `best_model.joblib` – сохранённая лучшая модель;
- `best_model_meta.json` – метаданные: какая модель лучшая, какими параметрами, какие метрики на test;
- `figures/` – минимум 2 изображения (например, ROC/PR + confusion matrix или importance).

---

### 2.5. Отчёт `report.md` (обязательно)

1) В материалах семинара будет шаблон: `S06-hw-report-template.md`.  
2) Нужно создать файл `homeworks/HW06/report.md` и заполнить его **по шаблону**.

Важно:

- не меняйте названия разделов (заголовков) в отчёте;
- вставляйте результаты и выводы в соответствующие секции.

---

## 3. Требования к структуре и именованию (итог)

К дедлайну в репозитории должно быть:

- `homeworks/HW06/HW06.ipynb`
- `homeworks/HW06/report.md`
- `homeworks/HW06/artifacts/` (см. состав выше)

Требования:

- названия папок и файлов – строго как указано;
- путь к CSV – относительный;
- ноутбук выполняется **без ошибок** при последовательном запуске всех ячеек;
- результаты эксперимента оформлены: метрики, сравнение моделей, выводы.

---

## 4. Критерии зачёта

HW06 считается зачтённым, если:

1) Соблюдена структура `homeworks/HW06/` и нейминг файлов.

2) В `HW06.ipynb` есть:

   - загрузка выбранного `S06-hw-dataset-0X.csv`;
   - базовый EDA и анализ баланса классов;
   - train/test-сплит с `random_state` и `stratify`;
   - baseline: Dummy + LogisticRegression;
   - минимум 3 модели недели 6 (дерево + лес + boosting), с подбором параметров на train через CV;
   - честная финальная оценка на test по согласованным метрикам;
   - интерпретация лучшей модели (permutation importance) + текстовые выводы.

3) В `artifacts/` лежат требуемые файлы и минимум 2 графика в `figures/`.

4) Заполнен `report.md` по шаблону.

---

## 5. Опциональная часть (для желающих)

Не обязательна для зачёта, но приветствуется:

- проверка **устойчивости**: несколько прогонов (например, 5 разных `random_state`) и анализ разброса метрик;
- PR-кривая и `average_precision_score` для датасета-04 (дисбаланс);
- калибровка вероятностей (`CalibratedClassifierCV`) и сравнение;
- сравнение времени обучения/инференса моделей.

---

## 6. Сроки и порядок сдачи

- Работа выполняется **индивидуально**.
- Дедлайн объявляется преподавателем отдельно.
- Факт сдачи: к дедлайну в репозитории есть `homeworks/HW06/` со всеми файлами и корректно выполненным ноутбуком.
